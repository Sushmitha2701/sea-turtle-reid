# ResNet-18 Configuration for Sea Turtle Re-Identification
# Optimal for efficient deployment with good balance

model:
  architecture: "resnet18"
  num_classes: 438
  pretrained: true
  feature_dim: 512
  dropout: 0.5

dataset:
  name: "SeaTurtleID2022"
  root: "data/SeaTurtleID2022"
  image_size: [256, 128]
  temporal_split:
    ratios: [0.7, 0.15, 0.15]
    ensure_zero_leakage: true

training:
  epochs: 25
  batch_size: 32
  num_workers: 4
  
  optimizer:
    type: "Adam"
    lr: 0.00035
    betas: [0.9, 0.999]
    weight_decay: 0.0005
  
  scheduler:
    type: "StepLR"
    step_size: 10
    gamma: 0.1
  
  loss:
    cross_entropy_weight: 1.0
    triplet_weight: 0.5
    center_weight: 0.0005
    triplet_margin: 0.3
    
  class_weights: true
  balanced_sampling: false

augmentation:
  train:
    - RandomHorizontalFlip: {p: 0.5}
    - RandomCrop: {size: [256, 128], padding: 10}
    - ColorJitter: {brightness: 0.1, contrast: 0.1, saturation: 0.1}
    - ToTensor: {}
    - Normalize: {mean: [0.485, 0.456, 0.406], std: [0.229, 0.224, 0.225]}
  
  test:
    - Resize: {size: [256, 128]}
    - ToTensor: {}
    - Normalize: {mean: [0.485, 0.456, 0.406], std: [0.229, 0.224, 0.225]}

evaluation:
  distance_metric: "euclidean"
  max_rank: 50
  rerank: false

logging:
  tensorboard: true
  wandb: false
  print_freq: 10
  eval_freq: 1
  save_freq: 5

checkpoint:
  save_best: true
  save_last: true
  metric: "rank-1"

# Expected Performance (from dissertation)
# Rank-1: 1.30%
# Rank-5: 8.57%
# Rank-10: 13.18%
# Rank-20: 22.19%  # Best at Rank-20!
# mAP: 0.0277
# Training time: ~29 minutes on Tesla T4
# Memory: 8.4GB (38% less than ResNet-50)
